{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ab93fb-3562-4eaf-bff4-d4fc9ab0732e",
   "metadata": {},
   "source": [
    "DOI: https://github.com/wri/global-pasture-watch/tree/main/ggc-30m\n",
    "\n",
    "O escopo de trabalho consiste em rodar uma série de análises de sensibilidade utilizando as amostras do Global Pasture Watch, especificamente o arquivo gpw_grassland_fscs.vi.vhr.overlaid_point.samples_20000101_20221231_go_epsg.4326_v1.pq (disponível em https://doi.org/10.5281/zenodo.13952806 & Github).\n",
    "As amostras consistem em um conjunto de pontos, agrupados/clusterizados por regiões/tiles de 1 km, indicadas pela coluna vi_tile_id (para mais informações ver https://doi.org/10.21203/rs.3.rs-4514820/v3)\n",
    "Segue abaixo as informações para as análises:\n",
    "- Para fins de comparação, recomendo que você selecione aleatoriamente 20% dos tiles 1-km (aprox. 460,000 pontos), de forma que os 80% dos tiles que sobrarem sejam utilizados para calibração e treinamento dos modelos de ML. Utilize os 20% como conjunto de teste independente, garantindo uma comparação robusta e em sem viés.\n",
    "- Para todas as análise assuma como modelo baseline o RF treinando com os hyper-parameteros do GPW. Esse foi o modelo que utilizamos para gerar o mapas de grassland v1. Todas as comparações devem includir F1-Score, log_loss, recall_score & precision_score por classe e geral.\n",
    "- Para rodar as análises com esse volume de dados você precisará ter acesso a um servidor robusto (64 GB of RAM & >32 threads) Veja com o @Laerte Ferreira quem pode lhe ajudar com isso no LAPIG. \n",
    "\n",
    "Segue abaixo as análises a serem implementadas:\n",
    "\n",
    "- Treinar um modelo LightGBM (com early_stopping) e comparar com o modelo baseline \n",
    "- Treinar um modelo RF para cada continente e comparar com o modelo baseline. Nessa análise, você precisa adicionar uma coluna continente no conjunto de treinamento e teste (veja geopandas.sjoin). Para o conjunto de teste, a coluna continente deve ser utilizada para encontrar o modelo local previamente treinado\n",
    "- Treinar vários modelos RF aumentando graduamente o número de amostras em cada tile (10, 25, 50, 75 e 100%) e comparar com o modelo baseline\n",
    "- Treinar um modelo RF com número de amostras iguais para todas as 3 classes (ex: exatamente 200,000 amostras para 1-cultivated grassland, 2-natural/semi-natural grassland e 3-others) e comparar com o modelo baseline.\n",
    "- Treinar um modelo RF removendo outliers (Ex: Novelty and Outlier Detection) e comparar com o modelo baseline.\n",
    "\n",
    "Análises adicionais propostas por você são bem-vindas :)\n",
    "\n",
    "Remoção de Outliers:\n",
    "\n",
    "- pyod\n",
    "- isolation forest\n",
    "\n",
    "Link: https://scikit-learn.org/1.5/modules/outlier_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df04bc-cd6c-4abf-9e6f-e7c1da2be89f",
   "metadata": {},
   "source": [
    "# Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbeea2cf-18aa-476e-a4e6-ad0133952d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SAMPLES_FILE_PATH = \"c_samples.pq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df78d110-05e6-4f7c-b7de-832f5e9e7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    samples = pd.read_parquet(SAMPLES_FILE_PATH)\n",
    "\n",
    "    return samples.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f6c23-7b6e-4ea1-87bc-dae2ca315410",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8ec57a-0055-426c-971f-533544ca8dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class PathHandler():\n",
    "    __path: str = ''\n",
    "    __value: str = ''\n",
    "    \n",
    "    @classmethod\n",
    "    def generate_path(cls, file_name: str):\n",
    "        return f'{cls.__path}/{file_name}_{cls.__value}.lz4'\n",
    "    \n",
    "    @classmethod\n",
    "    def get_path(cls):\n",
    "        return cls.__path\n",
    "    \n",
    "    @classmethod\n",
    "    def set_path(cls, path: str):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        PathHandler.__path = path\n",
    "        \n",
    "    @classmethod\n",
    "    def set_value(cls, value: str):\n",
    "        cls.__value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cafae04-defd-40bc-abe3-1846241dd58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_execution_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        begin = time.time()\n",
    "        resultado = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print('\\n\\n' + f'| Tempo de execução de {func.__name__}: {end - begin:.4f} segundos |'.center(200, '-') + '\\n\\n')\n",
    "        return resultado\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe796e8-48e6-4860-9dd9-263afa2baf81",
   "metadata": {},
   "source": [
    "# Trainamento do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd0290-1cd1-4673-b3f7-f89ff7ddaf83",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96819d5-9c27-4258-955f-9d05afde52a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import sys\n",
    "\n",
    "from scipy.signal import argrelmin\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, GroupKFold, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cf056-f5bb-4c02-8eee-71748fa2e87d",
   "metadata": {},
   "source": [
    "## Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a414c655-19d9-4c63-9fc3-0107d4c336c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COVARIATE_START_COLUMN = 'ml_type'\n",
    "SPATIAL_CROSS_VALIDATION_COLUMN = 'ml_cv_group'\n",
    "\n",
    "CROSS_VALIDATION_NJOBS, CROSS_VALIDATION_FOLDS = 5, 5\n",
    "\n",
    "TARGET_COLUMN = 'class'\n",
    "\n",
    "RANDOM_STATE = 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb75e6e1-e414-4c14-889e-819c67decfb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_covariates(samples: pd.DataFrame):\n",
    "    covariates = samples.columns\n",
    "    \n",
    "    return samples.columns[np.logical_or.reduce([\n",
    "        covariates.str.contains('accessibility'),\n",
    "        covariates.str.contains('blue'),\n",
    "        covariates.str.contains('bsf'),\n",
    "        covariates.str.contains('bsi'),\n",
    "        covariates.str.contains('clm'),\n",
    "        covariates.str.contains('dtm'),\n",
    "        covariates.str.contains('evi'),\n",
    "        covariates.str.contains('fapar'),\n",
    "        covariates.str.contains('green'),\n",
    "        covariates.str.contains('ndti'),\n",
    "        covariates.str.contains('ndvi'),\n",
    "        covariates.str.contains('ndwi'),\n",
    "        covariates.str.contains('nir'),\n",
    "        covariates.str.contains('nirv'),\n",
    "        covariates.str.contains('red'),\n",
    "        covariates.str.contains('road.distance_osm.highways.high.density'),\n",
    "        covariates.str.contains('road.distance_osm.highways.low.density'),\n",
    "        covariates.str.contains('swir1'),\n",
    "        covariates.str.contains('swir2'),\n",
    "        covariates.str.contains('thermal'),\n",
    "        covariates.str.contains('water.distance_glad.interanual.dynamic.classes'),\n",
    "        covariates.str.contains('wv_mcd19a2v061')\n",
    "    ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99ac300-f5a3-46a4-bec0-65b718c93e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target_ovo(samples: pd.DataFrame, class_name: str, class_a: list[int], class_b: list[int]):\n",
    "    remap_dict = {}\n",
    "    \n",
    "    remap_dict.update({val: 0 for val in class_a})\n",
    "    remap_dict.update({val: 1 for val in class_b})\n",
    "    \n",
    "    samples[class_name] = samples[TARGET_COLUMN].map(remap_dict)\n",
    "\n",
    "\n",
    "def create_ovo_class(samples: pd.DataFrame, class_name: list[str], class_values: list[tuple[list[int], list[int]]]):\n",
    "    class_data = dict(zip(class_name, class_values))\n",
    "    \n",
    "    for class_key in class_data:\n",
    "        value_a = class_data[class_key][0]\n",
    "        value_b = class_data[class_key][1]\n",
    "        \n",
    "        target_ovo(samples, class_key, value_a, value_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4820e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_threshold(y_true: pd.DataFrame, y_pred):\n",
    "    precision, recall, threshold = precision_recall_curve(y_true, y_pred)\n",
    "    \n",
    "    nonzero_mask = np.logical_and((precision != 0.0), (recall != 0.0))\n",
    "    \n",
    "    optimal_idx = np.argmax(1 - np.abs(precision[nonzero_mask] - recall[nonzero_mask]))\n",
    "    \n",
    "    return threshold[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa91efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator():\n",
    "    return RandomForestClassifier(n_estimators=60, n_jobs=-1)\n",
    "\n",
    "\n",
    "def random_forest(samples: pd.DataFrame, target_column: str, covariates: list[str], continent: str):\n",
    "    tc_samples = samples[np.logical_not(np.isnan(samples[target_column]))]\n",
    "\n",
    "    X = tc_samples[tc_samples['continent'] == continent][covariates]\n",
    "    y = tc_samples[tc_samples['continent'] == continent][target_column]\n",
    "\n",
    "    groupKFold = GroupKFold(CROSS_VALIDATION_FOLDS)\n",
    "\n",
    "    y_true = []\n",
    "\n",
    "    b_pred_proba = []\n",
    "    c_pred_proba = []\n",
    "\n",
    "    for train_idx, test_idx in groupKFold.split(X, y, tc_samples[tc_samples['continent'] == continent][SPATIAL_CROSS_VALIDATION_COLUMN]):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        B_train = tc_samples[~tc_samples.index.isin(X_test.index)][covariates]\n",
    "        b_train = tc_samples[~tc_samples.index.isin(X_test.index)][target_column]\n",
    "\n",
    "        b_estimator = get_estimator()\n",
    "        c_estimator = get_estimator()\n",
    "        b_estimator.fit(B_train, b_train)\n",
    "        c_estimator.fit(X_train, y_train)\n",
    "\n",
    "        y_true.extend(list(y_test))\n",
    "        b_pred_proba.extend(b_estimator.predict_proba(X_test)[:,1])\n",
    "        c_pred_proba.extend(c_estimator.predict_proba(X_test)[:,1])\n",
    "\n",
    "    b_op_threshold = get_optimal_threshold(y_true, b_pred_proba)\n",
    "    c_op_threshold = get_optimal_threshold(y_true, c_pred_proba)\n",
    "\n",
    "    b_pred = (b_pred_proba >= b_op_threshold).astype(int)\n",
    "    c_pred = (c_pred_proba >= c_op_threshold).astype(int)\n",
    "\n",
    "    joblib.dump({\n",
    "        'cv_result': pd.DataFrame({\n",
    "            'baseline_predict_proba': b_pred_proba,\n",
    "            'continent_predict_proba': c_pred_proba,\n",
    "            'expected': y.to_numpy(),\n",
    "        }),\n",
    "        'baseline': {\n",
    "            'threshold': b_op_threshold,\n",
    "            'recall': recall_score(y_true, b_pred),\n",
    "            'precision': precision_score(y_true, b_pred),\n",
    "            'f1_score': f1_score(y_true, b_pred),\n",
    "        },\n",
    "        'continent': {\n",
    "            'threshold': c_op_threshold,\n",
    "            'recall': recall_score(y_true, c_pred),\n",
    "            'precision': precision_score(y_true, c_pred),\n",
    "            'f1_score': f1_score(y_true, c_pred),\n",
    "        }\n",
    "    }, PathHandler.generate_path('model'), compress='lz4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2792a96-9984-4976-a76f-7c7236188d4b",
   "metadata": {},
   "source": [
    "# Treinamento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59709b11-30af-4488-80ee-7d14f82ecfda",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_name = ['other_vs_cultivated', 'other_vs_natural']\n",
    "class_values = [([3], [1]), ([3], [2])]\n",
    "\n",
    "for continent in ['Asia', 'North America', 'South America', 'Africa', 'Europe', 'Australia', 'Oceania']:\n",
    "    PathHandler.set_path(f'random_forest/continents')\n",
    "    \n",
    "    samples = get_samples()\n",
    "\n",
    "    covariates = pd.read_csv('covariates.csv')['covariates']\n",
    "\n",
    "    create_ovo_class(samples, class_name, class_values)\n",
    "\n",
    "    for target_column in class_name:\n",
    "        b_estimator = joblib.load(f\"random_forest/baseline/model_{target_column}.lz4\")['model']\n",
    "\n",
    "        PathHandler.set_value(f\"{continent.lower().replace(' ', '_')}_\" + target_column)\n",
    "        \n",
    "        random_forest(samples, target_column, covariates, continent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd3421-08ac-4082-92af-93c94c89eaee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
