{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1df04bc-cd6c-4abf-9e6f-e7c1da2be89f",
   "metadata": {},
   "source": [
    "# Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbeea2cf-18aa-476e-a4e6-ad0133952d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "SAMPLES_FILE_PATH = \"samples.pq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f567fe7-1b25-45c8-91c1-563e7df5c7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    samples = pd.read_parquet(SAMPLES_FILE_PATH)\n",
    "    \n",
    "    return samples.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f6c23-7b6e-4ea1-87bc-dae2ca315410",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8ec57a-0055-426c-971f-533544ca8dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class PathHandler():\n",
    "    __path: str = ''\n",
    "    __value: str = ''\n",
    "    \n",
    "    @classmethod\n",
    "    def generate_path(cls, file_name: str):\n",
    "        return f'{cls.__path}/{file_name}_{cls.__value}.lz4'\n",
    "    \n",
    "    @classmethod\n",
    "    def get_path(cls):\n",
    "        return cls.__path\n",
    "    \n",
    "    @classmethod\n",
    "    def set_path(cls, path: str):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        PathHandler.__path = path\n",
    "        \n",
    "    @classmethod\n",
    "    def set_value(cls, value: str):\n",
    "        cls.__value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cafae04-defd-40bc-abe3-1846241dd58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_execution_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        begin = time.time()\n",
    "        resultado = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print('\\n\\n' + f'| Tempo de execução de {func.__name__}: {end - begin:.4f} segundos |'.center(200, '-') + '\\n\\n')\n",
    "        return resultado\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe796e8-48e6-4860-9dd9-263afa2baf81",
   "metadata": {},
   "source": [
    "# Trainamento do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd0290-1cd1-4673-b3f7-f89ff7ddaf83",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96819d5-9c27-4258-955f-9d05afde52a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import sys\n",
    "\n",
    "from scipy.signal import argrelmin\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, GroupKFold, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cf056-f5bb-4c02-8eee-71748fa2e87d",
   "metadata": {},
   "source": [
    "## Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a414c655-19d9-4c63-9fc3-0107d4c336c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COVARIATE_START_COLUMN = 'ml_type'\n",
    "SPATIAL_CROSS_VALIDATION_COLUMN = 'ml_cv_group'\n",
    "\n",
    "CROSS_VALIDATION_NJOBS, CROSS_VALIDATION_FOLDS = 5, 5\n",
    "\n",
    "TARGET_COLUMN = 'class'\n",
    "\n",
    "RANDOM_STATE = 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb75e6e1-e414-4c14-889e-819c67decfb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_covariates(samples: pd.DataFrame):\n",
    "    covariates = samples.columns\n",
    "    \n",
    "    return samples.columns[np.logical_or.reduce([\n",
    "        covariates.str.contains('accessibility'),\n",
    "        covariates.str.contains('blue'),\n",
    "        covariates.str.contains('bsf'),\n",
    "        covariates.str.contains('bsi'),\n",
    "        covariates.str.contains('clm'),\n",
    "        covariates.str.contains('dtm'),\n",
    "        covariates.str.contains('evi'),\n",
    "        covariates.str.contains('fapar'),\n",
    "        covariates.str.contains('green'),\n",
    "        covariates.str.contains('ndti'),\n",
    "        covariates.str.contains('ndvi'),\n",
    "        covariates.str.contains('ndwi'),\n",
    "        covariates.str.contains('nir'),\n",
    "        covariates.str.contains('nirv'),\n",
    "        covariates.str.contains('red'),\n",
    "        covariates.str.contains('road.distance_osm.highways.high.density'),\n",
    "        covariates.str.contains('road.distance_osm.highways.low.density'),\n",
    "        covariates.str.contains('swir1'),\n",
    "        covariates.str.contains('swir2'),\n",
    "        covariates.str.contains('thermal'),\n",
    "        covariates.str.contains('water.distance_glad.interanual.dynamic.classes'),\n",
    "        covariates.str.contains('wv_mcd19a2v061')\n",
    "    ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99ac300-f5a3-46a4-bec0-65b718c93e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target_ovo(samples: pd.DataFrame, class_name: str, class_a: list[int], class_b: list[int]):\n",
    "    remap_dict = {}\n",
    "    \n",
    "    remap_dict.update({val: 0 for val in class_a})\n",
    "    remap_dict.update({val: 1 for val in class_b})\n",
    "    \n",
    "    samples[class_name] = samples[TARGET_COLUMN].map(remap_dict)\n",
    "\n",
    "\n",
    "def create_ovo_class(samples: pd.DataFrame, class_name: list[str], class_values: list[tuple[list[int], list[int]]]):\n",
    "    class_data = dict(zip(class_name, class_values))\n",
    "    \n",
    "    for class_key in class_data:\n",
    "        value_a = class_data[class_key][0]\n",
    "        value_b = class_data[class_key][1]\n",
    "        \n",
    "        target_ovo(samples, class_key, value_a, value_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4820e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_threshold(y_true: pd.DataFrame, y_pred):\n",
    "    precision, recall, threshold = precision_recall_curve(y_true, y_pred)\n",
    "    \n",
    "    nonzero_mask = np.logical_and((precision != 0.0), (recall != 0.0))\n",
    "    \n",
    "    optimal_idx = np.argmax(1 - np.abs(precision[nonzero_mask] - recall[nonzero_mask]))\n",
    "    \n",
    "    return threshold[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03f3f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator():\n",
    "    return RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "def random_forest_undersampling_random(samples: pd.DataFrame, target_column: str, covariates: list[str]):\n",
    "    tc_samples = samples[np.logical_not(np.isnan(samples[target_column]))].reset_index()\n",
    "\n",
    "    X = tc_samples[covariates]\n",
    "    y = tc_samples[target_column]\n",
    "\n",
    "    groupKFold = GroupKFold(CROSS_VALIDATION_FOLDS)\n",
    "\n",
    "    y_true = []\n",
    "    y_pred_proba = []\n",
    "\n",
    "    for train_idx, test_idx in groupKFold.split(X, y, tc_samples[SPATIAL_CROSS_VALIDATION_COLUMN]):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "        estimator = get_estimator()\n",
    "        estimator.fit(X_train_res, y_train_res)\n",
    "\n",
    "        y_true.extend(list(y_test))\n",
    "        y_pred_proba.extend(estimator.predict_proba(X_test)[:,1])\n",
    "\n",
    "    op_threshold = get_optimal_threshold(y_true, y_pred_proba)\n",
    "\n",
    "    y_pred = (y_pred_proba >= op_threshold).astype(int)\n",
    "\n",
    "    joblib.dump({\n",
    "        'cv_result': pd.DataFrame({\n",
    "            'predict_proba': y_pred_proba,\n",
    "            'expected': y.to_numpy(),\n",
    "        }),\n",
    "        'threshold': op_threshold,\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'model': estimator,\n",
    "    }, PathHandler.generate_path('model'), compress='lz4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf338d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_undersampling_centroid(samples: pd.DataFrame, target_column: str, covariates: list[str]):\n",
    "    tc_samples = samples[np.logical_not(np.isnan(samples[target_column]))].reset_index()\n",
    "\n",
    "    X = tc_samples[covariates]\n",
    "    y = tc_samples[target_column]\n",
    "\n",
    "    groupKFold = GroupKFold(CROSS_VALIDATION_FOLDS)\n",
    "\n",
    "    y_true = []\n",
    "    y_pred_proba = []\n",
    "\n",
    "    for train_idx, test_idx in groupKFold.split(X, y, tc_samples[SPATIAL_CROSS_VALIDATION_COLUMN]):\n",
    "        print(\"Começando processamento...\")\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        cc = ClusterCentroids(random_state=42)\n",
    "        X_train_res, y_train_res = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "        estimator = get_estimator()\n",
    "        estimator.fit(X_train_res, y_train_res)\n",
    "\n",
    "        y_true.extend(list(y_test))\n",
    "        y_pred_proba.extend(estimator.predict_proba(X_test)[:,1])\n",
    "\n",
    "    op_threshold = get_optimal_threshold(y_true, y_pred_proba)\n",
    "\n",
    "    y_pred = (y_pred_proba >= op_threshold).astype(int)\n",
    "\n",
    "    joblib.dump({\n",
    "        'cv_result': pd.DataFrame({\n",
    "            'predict_proba': y_pred_proba,\n",
    "            'expected': y.to_numpy(),\n",
    "        }),\n",
    "        'threshold': op_threshold,\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'model': estimator,\n",
    "    }, PathHandler.generate_path('model'), compress='lz4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ca83bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_oversampling(samples: pd.DataFrame, target_column: str, covariates: list[str]):\n",
    "    tc_samples = samples[np.logical_not(np.isnan(samples[target_column]))].reset_index()\n",
    "\n",
    "    X = tc_samples[covariates]\n",
    "    y = tc_samples[target_column]\n",
    "\n",
    "    groupKFold = GroupKFold(CROSS_VALIDATION_FOLDS)\n",
    "\n",
    "    y_true = []\n",
    "    y_pred_proba = []\n",
    "\n",
    "    for train_idx, test_idx in groupKFold.split(X, y, tc_samples[SPATIAL_CROSS_VALIDATION_COLUMN]):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        estimator = get_estimator()\n",
    "        estimator.fit(X_resampled, y_resampled)\n",
    "\n",
    "        y_true.extend(list(y_test))\n",
    "        y_pred_proba.extend(estimator.predict_proba(X_test)[:,1])\n",
    "\n",
    "    op_threshold = get_optimal_threshold(y_true, y_pred_proba)\n",
    "\n",
    "    y_pred = (y_pred_proba >= op_threshold).astype(int)\n",
    "\n",
    "    joblib.dump({\n",
    "        'cv_result': pd.DataFrame({\n",
    "            'predict_proba': y_pred_proba,\n",
    "            'expected': y.to_numpy(),\n",
    "        }),\n",
    "        'threshold': op_threshold,\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'model': estimator,\n",
    "    }, PathHandler.generate_path('model'), compress='lz4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2792a96-9984-4976-a76f-7c7236188d4b",
   "metadata": {},
   "source": [
    "# Treinamento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0e45ff6-968f-4ca6-b7e8-cb6c5f35dcf5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_name = ['other_vs_cultivated', 'other_vs_natural']\n",
    "class_values = [([3], [1]), ([3], [2])]\n",
    "\n",
    "PathHandler.set_path(f'random_forest/balanced')\n",
    "\n",
    "samples = get_samples()\n",
    "\n",
    "covariates = get_covariates(samples)\n",
    "\n",
    "create_ovo_class(samples, class_name, class_values)\n",
    "\n",
    "for target_column in class_name:\n",
    "    PathHandler.set_value(\"random_\" + target_column)\n",
    "    \n",
    "    random_forest_undersampling_random(samples, target_column, covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23d16c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target_column \u001b[38;5;129;01min\u001b[39;00m class_name:\n\u001b[32m     13\u001b[39m     PathHandler.set_value(\u001b[33m\"\u001b[39m\u001b[33mcentroid_\u001b[39m\u001b[33m\"\u001b[39m + target_column)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mrandom_forest_undersampling_centroid\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariates\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mrandom_forest_undersampling_centroid\u001b[39m\u001b[34m(samples, target_column, covariates)\u001b[39m\n\u001b[32m     14\u001b[39m y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\u001b[32m     16\u001b[39m cc = ClusterCentroids(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m X_train_res, y_train_res = \u001b[43mcc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m estimator = get_estimator()\n\u001b[32m     20\u001b[39m estimator.fit(X_train_res, y_train_res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:202\u001b[39m, in \u001b[36mBaseSampler.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **params):\n\u001b[32m    182\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m \u001b[33;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:105\u001b[39m, in \u001b[36mSamplerMixin.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m     99\u001b[39m X, y, binarize_y = \u001b[38;5;28mself\u001b[39m._check_X_y(X, y)\n\u001b[32m    101\u001b[39m \u001b[38;5;28mself\u001b[39m.sampling_strategy_ = check_sampling_strategy(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m.sampling_strategy, y, \u001b[38;5;28mself\u001b[39m._sampling_type\n\u001b[32m    103\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m y_ = (\n\u001b[32m    108\u001b[39m     label_binarize(output[\u001b[32m1\u001b[39m], classes=np.unique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[32m1\u001b[39m]\n\u001b[32m    109\u001b[39m )\n\u001b[32m    111\u001b[39m X_, y_ = arrays_transformer.transform(output[\u001b[32m0\u001b[39m], y_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py:178\u001b[39m, in \u001b[36mClusterCentroids._fit_resample\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    176\u001b[39m n_samples = \u001b[38;5;28mself\u001b[39m.sampling_strategy_[target_class]\n\u001b[32m    177\u001b[39m \u001b[38;5;28mself\u001b[39m.estimator_.set_params(**{\u001b[33m\"\u001b[39m\u001b[33mn_clusters\u001b[39m\u001b[33m\"\u001b[39m: n_samples})\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_class_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator_, \u001b[33m\"\u001b[39m\u001b[33mcluster_centers_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    181\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`estimator` should be a clustering estimator exposing a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfitted parameter `cluster_centers_`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    183\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1499\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1495\u001b[39m best_inertia, best_labels = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m._n_init):\n\u001b[32m   1498\u001b[39m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1499\u001b[39m     centers_init = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m   1507\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitialization complete\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1014\u001b[39m, in \u001b[36m_BaseKMeans._init_centroids\u001b[39m\u001b[34m(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)\u001b[39m\n\u001b[32m   1011\u001b[39m     sample_weight = sample_weight[init_indices]\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init == \u001b[33m\"\u001b[39m\u001b[33mk-means++\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     centers, _ = \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init == \u001b[33m\"\u001b[39m\u001b[33mrandom\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1022\u001b[39m     seeds = random_state.choice(\n\u001b[32m   1023\u001b[39m         n_samples,\n\u001b[32m   1024\u001b[39m         size=n_clusters,\n\u001b[32m   1025\u001b[39m         replace=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1026\u001b[39m         p=sample_weight / sample_weight.sum(),\n\u001b[32m   1027\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:251\u001b[39m, in \u001b[36m_kmeans_plusplus\u001b[39m\u001b[34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001b[39m\n\u001b[32m    248\u001b[39m np.clip(candidate_ids, \u001b[38;5;28;01mNone\u001b[39;00m, closest_dist_sq.size - \u001b[32m1\u001b[39m, out=candidate_ids)\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# Compute distances to center candidates\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m distance_to_candidates = \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    253\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# update closest distances squared and potential for each candidate\u001b[39;00m\n\u001b[32m    256\u001b[39m np.minimum(closest_dist_sq, distance_to_candidates, out=distance_to_candidates)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:424\u001b[39m, in \u001b[36m_euclidean_distances\u001b[39m\u001b[34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[39m\n\u001b[32m    421\u001b[39m     distances = _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     distances = -\u001b[32m2\u001b[39m * \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m     distances += XX\n\u001b[32m    426\u001b[39m     distances += YY\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:206\u001b[39m, in \u001b[36msafe_sparse_dot\u001b[39m\u001b[34m(a, b, dense_output)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m     ret = a @ b\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m sparse.issparse(b)\n\u001b[32m    208\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[32m    209\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[33m\"\u001b[39m\u001b[33mtoarray\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    210\u001b[39m ):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.toarray()\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tiago\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\_base.py:1388\u001b[39m, in \u001b[36missparse\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1382\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A namespace class to separate sparray from spmatrix\"\"\"\u001b[39;00m\n\u001b[32m   1385\u001b[39m sparray.\u001b[34m__doc__\u001b[39m = _spbase.\u001b[34m__doc__\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34missparse\u001b[39m(x):\n\u001b[32m   1389\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[32m   1390\u001b[39m \n\u001b[32m   1391\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1417\u001b[39m \u001b[33;03m    False\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "class_name = ['other_vs_cultivated', 'other_vs_natural']\n",
    "class_values = [([3], [1]), ([3], [2])]\n",
    "\n",
    "PathHandler.set_path(f'random_forest/balanced')\n",
    "\n",
    "samples = get_samples()\n",
    "\n",
    "covariates = get_covariates(samples)\n",
    "\n",
    "create_ovo_class(samples, class_name, class_values)\n",
    "\n",
    "for target_column in class_name:\n",
    "    PathHandler.set_value(\"centroid_\" + target_column)\n",
    "    \n",
    "    random_forest_undersampling_centroid(samples, target_column, covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691b5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = ['other_vs_cultivated', 'other_vs_natural']\n",
    "class_values = [([3], [1]), ([3], [2])]\n",
    "\n",
    "PathHandler.set_path(f'random_forest/balanced')\n",
    "\n",
    "samples = get_samples()\n",
    "\n",
    "covariates = get_covariates(samples)\n",
    "\n",
    "create_ovo_class(samples, class_name, class_values)\n",
    "\n",
    "for target_column in class_name:\n",
    "    PathHandler.set_value(\"smote_\" + target_column)\n",
    "    \n",
    "    random_forest_oversampling(samples, target_column, covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd3421-08ac-4082-92af-93c94c89eaee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
